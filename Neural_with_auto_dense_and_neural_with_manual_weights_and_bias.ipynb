{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    \n",
    "    val = pd.read_csv(path)\n",
    "    \n",
    "    val.drop(columns=['PassengerId','Name','Ticket','Pclass','Fare'], inplace=True)\n",
    "    val.replace(['male','female'], [1,0],inplace=True)\n",
    "    \n",
    "    embar_val = pd.DataFrame({'S' : val.Embarked == 'S','C' : val.Embarked == 'C','Q' : val.Embarked == 'Q','NAN' : val.Embarked == 'nan'}).astype(int)\n",
    "    val = val.drop('Embarked',axis=1)\n",
    "    \n",
    "    alone = pd.DataFrame({'alone' : val.Parch + val.SibSp == 0}).astype(int)\n",
    "    #val = val.drop(['Parch','SibSp'],axis=1)\n",
    "    val = pd.concat([val,embar_val,alone], axis=1, join='inner')\n",
    "    val['Cabin'].fillna('X', inplace = True)\n",
    "    val['Cabin_encoded'] = val['Cabin'].apply(lambda x:x[0] if len(x) > 1 else x)\n",
    "    \n",
    "    t = pd.DataFrame({'X' : val.Cabin_encoded == 'X','C' : val.Cabin_encoded == 'C','E' : val.Cabin_encoded == 'E','G':val.Cabin_encoded == 'G','D':val.Cabin_encoded == 'D','A': val.Cabin_encoded == 'A','B': val.Cabin_encoded == 'B','F': val.Cabin_encoded == 'F','T':val.Cabin_encoded == 'T'}).astype(int)\n",
    "    val.Age.fillna(0,inplace=True)\n",
    "    val = pd.concat([val, t], axis=1, join='inner')\n",
    "    val = val.drop(['Cabin_encoded','Cabin'],axis=1)\n",
    "    \n",
    "    if 'Survived' in val.columns:\n",
    "        global survive\n",
    "        survive = val.Survived\n",
    "        val.drop('Survived', inplace=True, axis=1)\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess('data/train.csv')\n",
    "train.head()\n",
    "\n",
    "test = preprocess('data/test.csv')\n",
    "y_test = pd.read_csv('data/surv_test.csv').iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaourab/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/gaourab/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/home/gaourab/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/gaourab/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train_x = train.as_matrix()\n",
    "train_y = pd.get_dummies(survive).as_matrix()\n",
    "\n",
    "test_x = test.as_matrix()\n",
    "test_y = pd.get_dummies(y_test).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 18)\n",
      "(418, 2)\n",
      "(891, 18)\n",
      "(891, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(test_x))\n",
    "print(np.shape(test_y))\n",
    "\n",
    "print(np.shape(train_x))\n",
    "print(np.shape(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_n = 1000\n",
    "class_n = 2\n",
    "bathc_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None,18])\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_model(x):\n",
    "    \n",
    "    layer1 = tf.layers.dense(x, units=100, activation=tf.nn.relu)\n",
    "    layer2 = tf.layers.dense(layer1, units=200, activation=tf.nn.relu)\n",
    "    drop = tf.layers.dropout(layer2, rate=0.5)\n",
    "    out = tf.layers.dense(drop, units=class_n)\n",
    "    \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-02d6f9b11280>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = n_model(x)\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=train_y, logits=pred)\n",
    "optimize = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "corr_pred = tf.equal(tf.argmax(pred,axis=1), tf.argmax(y, axis=1))\n",
    "acc = tf.reduce_mean(tf.cast(corr_pred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5598086\n",
      "0.36842105\n",
      "0.39473686\n",
      "0.47368422\n",
      "0.6650718\n",
      "0.64593303\n",
      "0.638756\n",
      "0.638756\n",
      "0.6411483\n",
      "0.6483254\n",
      "0.5861244\n",
      "0.46411484\n",
      "0.46411484\n",
      "0.59090906\n",
      "0.65311\n",
      "0.6363636\n",
      "0.6363636\n",
      "0.6363636\n",
      "0.6363636\n",
      "0.64593303\n",
      "0.7200957\n",
      "0.81100476\n",
      "0.80861247\n",
      "0.791866\n",
      "0.6985646\n",
      "0.6602871\n",
      "0.65311\n",
      "0.6698565\n",
      "0.7320574\n",
      "0.8181818\n",
      "0.78708136\n",
      "0.8014354\n",
      "0.77272725\n",
      "0.7583732\n",
      "0.7751196\n",
      "0.78708136\n",
      "0.784689\n",
      "0.78229666\n",
      "0.76555026\n",
      "0.791866\n",
      "0.784689\n",
      "0.77751195\n",
      "0.77751195\n",
      "0.78229666\n",
      "0.7751196\n",
      "0.7751196\n",
      "0.7703349\n",
      "0.77272725\n",
      "0.77751195\n",
      "0.76555026\n",
      "0.7631579\n",
      "0.7679426\n",
      "0.7703349\n",
      "0.7583732\n",
      "0.76076555\n",
      "0.76076555\n",
      "0.7583732\n",
      "0.7679426\n",
      "0.7703349\n",
      "0.77272725\n",
      "0.78229666\n",
      "0.78229666\n",
      "0.78229666\n",
      "0.78229666\n",
      "0.784689\n",
      "0.79425836\n",
      "0.7894737\n",
      "0.8181818\n",
      "0.82535887\n",
      "0.83253586\n",
      "0.8779904\n",
      "0.9019139\n",
      "0.9019139\n",
      "0.90909094\n",
      "0.9066986\n",
      "0.9114832\n",
      "0.9138756\n",
      "0.91626793\n",
      "0.923445\n",
      "0.92105263\n",
      "0.9282297\n",
      "0.923445\n",
      "0.9282297\n",
      "0.92583734\n",
      "0.9282297\n",
      "0.930622\n",
      "0.923445\n",
      "0.930622\n",
      "0.9282297\n",
      "0.930622\n",
      "0.93301433\n",
      "0.93301433\n",
      "0.930622\n",
      "0.930622\n",
      "0.9282297\n",
      "0.9282297\n",
      "0.9282297\n",
      "0.92583734\n",
      "0.930622\n",
      "0.9282297\n",
      "0.930622\n",
      "0.930622\n",
      "0.9282297\n",
      "0.930622\n",
      "0.923445\n",
      "0.93301433\n",
      "0.923445\n",
      "0.91626793\n",
      "0.9066986\n",
      "0.91626793\n",
      "0.90430623\n",
      "0.9114832\n",
      "0.8995215\n",
      "0.9114832\n",
      "0.90909094\n",
      "0.8995215\n",
      "0.90909094\n",
      "0.8971292\n",
      "0.9066986\n",
      "0.8899522\n",
      "0.9066986\n",
      "0.9066986\n",
      "0.8971292\n",
      "0.9138756\n",
      "0.8971292\n",
      "0.90430623\n",
      "0.9138756\n",
      "0.8971292\n",
      "0.9114832\n",
      "0.9114832\n",
      "0.8971292\n",
      "0.9114832\n",
      "0.90430623\n",
      "0.9019139\n",
      "0.90909094\n",
      "0.9019139\n",
      "0.9066986\n",
      "0.90909094\n",
      "0.8995215\n",
      "0.90909094\n",
      "0.90430623\n",
      "0.8947368\n",
      "0.9114832\n",
      "0.88755983\n",
      "0.9138756\n",
      "0.8971292\n",
      "0.8947368\n",
      "0.9114832\n",
      "0.8947368\n",
      "0.9066986\n",
      "0.90909094\n",
      "0.8899522\n",
      "0.9066986\n",
      "0.9066986\n",
      "0.8923445\n",
      "0.90909094\n",
      "0.9066986\n",
      "0.9019139\n",
      "0.90909094\n",
      "0.8923445\n",
      "0.90430623\n",
      "0.9066986\n",
      "0.8923445\n",
      "0.90430623\n",
      "0.90430623\n",
      "0.8947368\n",
      "0.90430623\n",
      "0.8947368\n",
      "0.90430623\n",
      "0.90430623\n",
      "0.8947368\n",
      "0.90430623\n",
      "0.9019139\n",
      "0.8971292\n",
      "0.9066986\n",
      "0.8947368\n",
      "0.9019139\n",
      "0.9019139\n",
      "0.8971292\n",
      "0.90430623\n",
      "0.8947368\n",
      "0.9019139\n",
      "0.9019139\n",
      "0.8971292\n",
      "0.90430623\n",
      "0.8971292\n",
      "0.9019139\n",
      "0.9019139\n",
      "0.8995215\n",
      "0.90430623\n",
      "0.8923445\n",
      "0.90430623\n",
      "0.8899522\n",
      "0.9066986\n",
      "0.8971292\n",
      "0.90430623\n",
      "0.9019139\n",
      "0.8923445\n",
      "0.9066986\n",
      "0.8899522\n",
      "0.9114832\n",
      "0.88755983\n",
      "0.9066986\n",
      "0.8995215\n",
      "0.8923445\n",
      "0.90430623\n",
      "0.88755983\n",
      "0.90430623\n",
      "0.8971292\n",
      "0.9019139\n",
      "0.9066986\n",
      "0.8923445\n",
      "0.90430623\n",
      "0.8923445\n",
      "0.90430623\n",
      "0.8995215\n",
      "0.8995215\n",
      "0.9066986\n",
      "0.8971292\n",
      "0.90430623\n",
      "0.9019139\n",
      "0.9019139\n",
      "0.8995215\n",
      "0.8971292\n",
      "0.90430623\n",
      "0.8899522\n",
      "0.90430623\n",
      "0.8947368\n",
      "0.90430623\n",
      "0.9019139\n",
      "0.8995215\n",
      "0.90430623\n",
      "0.8947368\n",
      "0.90430623\n",
      "0.8923445\n",
      "0.9019139\n",
      "0.8947368\n",
      "0.8995215\n",
      "0.8971292\n",
      "0.8971292\n",
      "0.9019139\n",
      "0.8947368\n",
      "0.90430623\n",
      "0.8899522\n",
      "0.9066986\n",
      "0.8851675\n",
      "0.9066986\n",
      "0.8899522\n",
      "0.9019139\n",
      "0.9019139\n",
      "0.8923445\n",
      "0.9066986\n",
      "0.8851675\n",
      "0.9019139\n",
      "0.8899522\n",
      "0.9019139\n",
      "0.8971292\n",
      "0.8851675\n",
      "0.8923445\n",
      "0.8779904\n",
      "0.90430623\n",
      "0.8995215\n",
      "0.8899522\n",
      "0.8971292\n",
      "0.88755983\n",
      "0.8995215\n",
      "0.9019139\n",
      "0.88755983\n",
      "0.8971292\n",
      "0.8923445\n",
      "0.8947368\n",
      "0.90430623\n",
      "0.88755983\n",
      "0.9019139\n",
      "0.9019139\n",
      "0.8899522\n",
      "0.8995215\n",
      "0.8947368\n",
      "0.8947368\n",
      "0.9019139\n",
      "0.8899522\n",
      "0.8995215\n",
      "0.8971292\n",
      "0.88755983\n",
      "0.8995215\n",
      "0.88755983\n",
      "0.8971292\n",
      "0.8971292\n",
      "0.8923445\n",
      "0.8995215\n",
      "0.8923445\n",
      "0.8923445\n",
      "0.88755983\n",
      "0.88755983\n",
      "0.8971292\n",
      "0.8923445\n",
      "0.90430623\n",
      "0.8923445\n",
      "0.88755983\n",
      "0.8923445\n",
      "0.8899522\n",
      "0.8971292\n",
      "0.88755983\n",
      "0.8923445\n",
      "0.8971292\n",
      "0.8899522\n",
      "0.8995215\n",
      "0.88755983\n",
      "0.8971292\n",
      "0.8851675\n",
      "0.8923445\n",
      "0.88755983\n",
      "0.8947368\n",
      "0.8803828\n",
      "0.8947368\n",
      "0.8803828\n",
      "0.8923445\n",
      "0.8851675\n",
      "0.8947368\n",
      "0.8899522\n",
      "0.8923445\n",
      "0.8899522\n",
      "0.88755983\n",
      "0.88755983\n",
      "0.88755983\n",
      "0.8899522\n",
      "0.88755983\n",
      "0.8899522\n",
      "0.8899522\n",
      "0.88755983\n",
      "0.8899522\n",
      "0.88755983\n",
      "0.8923445\n",
      "0.8803828\n",
      "0.8947368\n",
      "0.8732057\n",
      "0.8947368\n",
      "0.8755981\n",
      "0.8971292\n",
      "0.88755983\n",
      "0.8899522\n",
      "0.8851675\n",
      "0.8851675\n",
      "0.8827751\n",
      "0.88755983\n",
      "0.8899522\n",
      "0.88755983\n",
      "0.88755983\n",
      "0.88755983\n",
      "0.8827751\n",
      "0.88755983\n",
      "0.8851675\n",
      "0.8851675\n",
      "0.8851675\n",
      "0.8851675\n",
      "0.8851675\n",
      "0.88755983\n",
      "0.8827751\n",
      "0.8851675\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8851675\n",
      "0.88755983\n",
      "0.8851675\n",
      "0.8851675\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8755981\n",
      "0.8851675\n",
      "0.8684211\n",
      "0.8827751\n",
      "0.8779904\n",
      "0.8851675\n",
      "0.8827751\n",
      "0.8803828\n",
      "0.8851675\n",
      "0.8684211\n",
      "0.88755983\n",
      "0.8851675\n",
      "0.8851675\n",
      "0.8779904\n",
      "0.8755981\n",
      "0.8803828\n",
      "0.8827751\n",
      "0.8851675\n",
      "0.8779904\n",
      "0.8755981\n",
      "0.8732057\n",
      "0.8827751\n",
      "0.8803828\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8851675\n",
      "0.8779904\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8803828\n",
      "0.8827751\n",
      "0.8851675\n",
      "0.8803828\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8803828\n",
      "0.8827751\n",
      "0.8851675\n",
      "0.88755983\n",
      "0.8827751\n",
      "0.8803828\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8827751\n",
      "0.8851675\n",
      "0.8851675\n",
      "0.8827751\n",
      "0.8803828\n",
      "0.8803828\n",
      "0.8827751\n",
      "0.8851675\n",
      "0.8803828\n",
      "0.8827751\n",
      "0.8803828\n",
      "0.8803828\n",
      "0.8827751\n",
      "0.8803828\n",
      "0.8755981\n",
      "0.8779904\n",
      "0.8755981\n",
      "0.8803828\n",
      "0.8755981\n",
      "0.8803828\n",
      "0.8732057\n",
      "0.8803828\n",
      "0.87081337\n",
      "0.8779904\n",
      "0.8732057\n",
      "0.8827751\n",
      "0.8684211\n",
      "0.8779904\n",
      "0.8684211\n",
      "0.8803828\n",
      "0.87081337\n",
      "0.8779904\n",
      "0.8732057\n",
      "0.8779904\n",
      "0.8779904\n",
      "0.8803828\n",
      "0.8779904\n",
      "0.8732057\n",
      "0.8803828\n",
      "0.87081337\n",
      "0.8755981\n",
      "0.8660287\n",
      "0.8827751\n",
      "0.8636364\n",
      "0.8803828\n",
      "0.8660287\n",
      "0.8732057\n",
      "0.87081337\n",
      "0.8755981\n",
      "0.8732057\n",
      "0.8732057\n",
      "0.8779904\n",
      "0.8732057\n",
      "0.8779904\n",
      "0.87081337\n",
      "0.8755981\n",
      "0.8636364\n",
      "0.8732057\n",
      "0.8660287\n",
      "0.8779904\n",
      "0.8660287\n",
      "0.8779904\n",
      "0.87081337\n",
      "0.8755981\n",
      "0.87081337\n",
      "0.8779904\n",
      "0.87081337\n",
      "0.8755981\n",
      "0.87081337\n",
      "0.8660287\n",
      "0.8660287\n",
      "0.8684211\n",
      "0.8732057\n",
      "0.87081337\n",
      "0.8755981\n",
      "0.8732057\n",
      "0.8732057\n",
      "0.8660287\n",
      "0.8732057\n",
      "0.8516746\n",
      "0.8755981\n",
      "0.8516746\n",
      "0.8732057\n",
      "0.8684211\n",
      "0.8732057\n",
      "0.8660287\n",
      "0.87081337\n",
      "0.8732057\n",
      "0.8732057\n",
      "0.87081337\n",
      "0.861244\n",
      "0.87081337\n",
      "0.8516746\n",
      "0.8732057\n",
      "0.85406697\n",
      "0.8755981\n",
      "0.8564593\n",
      "0.8660287\n",
      "0.8684211\n",
      "0.8684211\n",
      "0.87081337\n",
      "0.8516746\n",
      "0.87081337\n",
      "0.8516746\n",
      "0.8755981\n",
      "0.84689\n",
      "0.87081337\n",
      "0.8684211\n",
      "0.8636364\n",
      "0.8732057\n",
      "0.85406697\n",
      "0.87081337\n",
      "0.8516746\n",
      "0.87081337\n",
      "0.87081337\n",
      "0.861244\n",
      "0.8684211\n",
      "0.8516746\n",
      "0.8684211\n",
      "0.87081337\n",
      "0.8684211\n",
      "0.8684211\n",
      "0.8564593\n",
      "0.8660287\n",
      "0.8588517\n",
      "0.8660287\n",
      "0.8660287\n",
      "0.861244\n",
      "0.8660287\n",
      "0.861244\n",
      "0.861244\n",
      "0.861244\n",
      "0.861244\n",
      "0.8660287\n",
      "0.8660287\n",
      "0.861244\n",
      "0.8636364\n",
      "0.8588517\n",
      "0.8636364\n",
      "0.861244\n",
      "0.8660287\n",
      "0.861244\n",
      "0.8660287\n",
      "0.861244\n",
      "0.861244\n",
      "0.861244\n",
      "0.8588517\n",
      "0.8588517\n",
      "0.8588517\n",
      "0.8588517\n",
      "0.8588517\n",
      "0.8588517\n",
      "0.861244\n",
      "0.8588517\n",
      "0.85406697\n",
      "0.8588517\n",
      "0.8588517\n",
      "0.8588517\n",
      "0.85406697\n",
      "0.861244\n",
      "0.85406697\n",
      "0.8588517\n",
      "0.8492823\n",
      "0.8588517\n",
      "0.85406697\n",
      "0.8516746\n",
      "0.8588517\n",
      "0.85406697\n",
      "0.8564593\n",
      "0.8516746\n",
      "0.8588517\n",
      "0.8516746\n",
      "0.861244\n",
      "0.85406697\n",
      "0.85406697\n",
      "0.8564593\n",
      "0.8492823\n",
      "0.85406697\n",
      "0.8492823\n",
      "0.861244\n",
      "0.8516746\n",
      "0.85406697\n",
      "0.8492823\n",
      "0.8516746\n",
      "0.85406697\n",
      "0.8516746\n",
      "0.8588517\n",
      "0.85406697\n",
      "0.8588517\n",
      "0.85406697\n",
      "0.85406697\n",
      "0.8516746\n",
      "0.8516746\n",
      "0.8492823\n",
      "0.8516746\n",
      "0.85406697\n",
      "0.85406697\n",
      "0.8588517\n",
      "0.8564593\n",
      "0.8660287\n",
      "0.8516746\n",
      "0.8564593\n",
      "0.8516746\n",
      "0.8588517\n",
      "0.8444976\n",
      "0.85406697\n",
      "0.8564593\n",
      "0.8516746\n",
      "0.8564593\n",
      "0.85406697\n",
      "0.8492823\n",
      "0.8444976\n",
      "0.8516746\n",
      "0.8492823\n",
      "0.8516746\n",
      "0.84689\n",
      "0.8564593\n",
      "0.8444976\n",
      "0.8564593\n",
      "0.8492823\n",
      "0.861244\n",
      "0.8516746\n",
      "0.8588517\n",
      "0.8492823\n",
      "0.85406697\n",
      "0.8444976\n",
      "0.8564593\n",
      "0.84689\n",
      "0.8516746\n",
      "0.8492823\n",
      "0.8516746\n",
      "0.85406697\n",
      "0.8516746\n",
      "0.85406697\n",
      "0.85406697\n",
      "0.8516746\n",
      "0.8516746\n",
      "0.8516746\n",
      "0.8492823\n",
      "0.8564593\n",
      "0.8444976\n",
      "0.85406697\n",
      "0.8492823\n",
      "0.8636364\n",
      "0.84210527\n",
      "0.8660287\n",
      "0.84210527\n",
      "0.8636364\n",
      "0.8516746\n",
      "0.8564593\n",
      "0.8516746\n",
      "0.8444976\n",
      "0.85406697\n",
      "0.8516746\n",
      "0.861244\n",
      "0.8492823\n",
      "0.8564593\n",
      "0.84689\n",
      "0.8492823\n",
      "0.8516746\n",
      "0.8444976\n",
      "0.8588517\n",
      "0.84689\n",
      "0.8588517\n",
      "0.84689\n",
      "0.8492823\n",
      "0.84689\n",
      "0.84689\n",
      "0.8588517\n",
      "0.8492823\n",
      "0.861244\n",
      "0.84689\n",
      "0.85406697\n",
      "0.8516746\n",
      "0.84689\n",
      "0.861244\n",
      "0.8492823\n",
      "0.861244\n",
      "0.84689\n",
      "0.8564593\n",
      "0.8492823\n",
      "0.85406697\n",
      "0.8516746\n",
      "0.8492823\n",
      "0.8564593\n",
      "0.8492823\n",
      "0.8588517\n",
      "0.8444976\n",
      "0.8516746\n",
      "0.84210527\n",
      "0.84689\n",
      "0.8516746\n",
      "0.84689\n",
      "0.8588517\n",
      "0.8492823\n",
      "0.8516746\n",
      "0.84689\n",
      "0.8516746\n",
      "0.8444976\n",
      "0.8492823\n",
      "0.84210527\n",
      "0.84689\n",
      "0.84689\n",
      "0.8444976\n",
      "0.8516746\n",
      "0.8444976\n",
      "0.84689\n",
      "0.8397129\n",
      "0.8516746\n",
      "0.8444976\n",
      "0.8516746\n",
      "0.8492823\n",
      "0.8564593\n",
      "0.8444976\n",
      "0.8636364\n",
      "0.8444976\n",
      "0.8660287\n",
      "0.8444976\n",
      "0.8636364\n",
      "0.8444976\n",
      "0.8564593\n",
      "0.8444976\n",
      "0.8444976\n",
      "0.84689\n",
      "0.8444976\n",
      "0.8564593\n",
      "0.8444976\n",
      "0.8636364\n",
      "0.84210527\n",
      "0.8660287\n",
      "0.8444976\n",
      "0.8588517\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.8444976\n",
      "0.8444976\n",
      "0.8444976\n",
      "0.84210527\n",
      "0.8516746\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.8444976\n",
      "0.8636364\n",
      "0.8444976\n",
      "0.861244\n",
      "0.84689\n",
      "0.8588517\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.84210527\n",
      "0.8492823\n",
      "0.84210527\n",
      "0.8492823\n",
      "0.84210527\n",
      "0.8444976\n",
      "0.8444976\n",
      "0.8397129\n",
      "0.84210527\n",
      "0.8397129\n",
      "0.84210527\n",
      "0.83732057\n",
      "0.84689\n",
      "0.84210527\n",
      "0.8516746\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.8444976\n",
      "0.8588517\n",
      "0.84210527\n",
      "0.87081337\n",
      "0.84210527\n",
      "0.87081337\n",
      "0.84210527\n",
      "0.8660287\n",
      "0.84689\n",
      "0.84689\n",
      "0.8492823\n",
      "0.8444976\n",
      "0.8636364\n",
      "0.8444976\n",
      "0.8636364\n",
      "0.84210527\n",
      "0.8516746\n",
      "0.8397129\n",
      "0.8444976\n",
      "0.85406697\n",
      "0.8444976\n",
      "0.8660287\n",
      "0.8444976\n",
      "0.8588517\n",
      "0.8444976\n",
      "0.8444976\n",
      "0.8444976\n",
      "0.8444976\n",
      "0.8564593\n",
      "0.84689\n",
      "0.8588517\n",
      "0.8444976\n",
      "0.85406697\n",
      "0.8444976\n",
      "0.8444976\n",
      "0.84210527\n",
      "0.84210527\n",
      "0.84210527\n",
      "0.8444976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8492823\n",
      "0.84689\n",
      "0.8516746\n",
      "0.84689\n",
      "0.85406697\n",
      "0.8444976\n",
      "0.8588517\n",
      "0.84689\n",
      "0.8564593\n",
      "0.8444976\n",
      "0.8564593\n",
      "0.84689\n",
      "0.8588517\n",
      "0.84689\n",
      "0.8516746\n",
      "0.84689\n",
      "0.861244\n",
      "0.8444976\n",
      "0.85406697\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.8444976\n",
      "0.8516746\n",
      "0.8397129\n",
      "0.8564593\n",
      "0.8444976\n",
      "0.8588517\n",
      "0.8444976\n",
      "0.8636364\n",
      "0.84210527\n",
      "0.861244\n",
      "0.8492823\n",
      "0.8588517\n",
      "0.84210527\n",
      "0.861244\n",
      "0.8397129\n",
      "0.8684211\n",
      "0.84689\n",
      "0.8660287\n",
      "0.8444976\n",
      "0.8564593\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.8397129\n",
      "0.8564593\n",
      "0.84210527\n",
      "0.8492823\n",
      "0.84210527\n",
      "0.8492823\n",
      "0.8444976\n",
      "0.85406697\n",
      "0.84210527\n",
      "0.861244\n",
      "0.84689\n",
      "0.8636364\n",
      "0.8492823\n",
      "0.861244\n",
      "0.84210527\n",
      "0.8636364\n",
      "0.84210527\n",
      "0.8660287\n",
      "0.84210527\n",
      "0.8636364\n",
      "0.84210527\n",
      "0.8564593\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.8444976\n",
      "0.8492823\n",
      "0.8444976\n",
      "0.84210527\n",
      "0.84210527\n",
      "0.8444976\n",
      "0.8397129\n",
      "0.8444976\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.8397129\n",
      "0.85406697\n",
      "0.84210527\n",
      "0.8588517\n",
      "0.8444976\n",
      "0.87081337\n",
      "0.8397129\n",
      "0.87081337\n",
      "0.84210527\n",
      "0.87081337\n",
      "0.8349282\n",
      "0.8492823\n",
      "0.8492823\n",
      "0.84210527\n",
      "0.861244\n",
      "0.8444976\n",
      "0.8636364\n",
      "0.84210527\n",
      "0.861244\n",
      "0.84210527\n",
      "0.84210527\n",
      "0.8444976\n",
      "0.84210527\n",
      "0.8564593\n",
      "0.8444976\n",
      "0.861244\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.84210527\n",
      "0.8444976\n",
      "0.84210527\n",
      "0.8397129\n",
      "0.84689\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.8397129\n",
      "0.8492823\n",
      "0.8397129\n",
      "0.8564593\n",
      "0.8397129\n",
      "0.8492823\n",
      "0.84210527\n",
      "0.8492823\n",
      "0.84210527\n",
      "0.8516746\n",
      "0.83732057\n",
      "0.85406697\n",
      "0.84210527\n",
      "0.8492823\n",
      "0.84210527\n",
      "0.84210527\n",
      "0.8444976\n",
      "0.8588517\n",
      "0.8397129\n",
      "0.8516746\n",
      "0.8397129\n",
      "0.8516746\n",
      "0.84210527\n",
      "0.85406697\n",
      "0.8397129\n",
      "0.85406697\n",
      "0.84210527\n",
      "0.8492823\n",
      "0.84689\n",
      "0.8564593\n",
      "0.83732057\n",
      "0.85406697\n",
      "0.8349282\n",
      "0.8516746\n",
      "0.8397129\n",
      "0.8516746\n",
      "0.8397129\n",
      "0.8492823\n",
      "0.8397129\n",
      "0.84689\n",
      "0.84210527\n",
      "0.84689\n",
      "0.83732057\n",
      "0.8516746\n",
      "0.8444976\n",
      "0.8516746\n",
      "0.83732057\n",
      "0.85406697\n",
      "0.83732057\n",
      "0.8588517\n",
      "0.8444976\n",
      "0.8588517\n",
      "0.8444976\n",
      "0.861244\n",
      "0.8444976\n",
      "0.8636364\n",
      "0.8444976\n",
      "0.8588517\n",
      "0.84210527\n",
      "0.8564593\n",
      "0.8397129\n",
      "0.8492823\n",
      "0.84210527\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(epoch_n):\n",
    "        sess.run(optimize, feed_dict = {x : train_x, y : train_y})\n",
    "        \n",
    "        acc_p = sess.run(acc, feed_dict = {x: test_x, y : test_y })\n",
    "        print(acc_p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manual weight and bias tutorial : https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network_raw.py'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"manual weight and bias tutorial : https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network_raw.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_1 = 100\n",
    "hidden_2 = 200\n",
    "\n",
    "input_shape = 18\n",
    "pred_class = 2\n",
    "\n",
    "x_ = tf.placeholder('float', shape=[None,input_shape])\n",
    "y_ = tf.placeholder('float', shape=[None,pred_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'w1' : tf.Variable(tf.random_normal([input_shape, hidden_1])),\n",
    "    'w2' : tf.Variable(tf.random_normal([hidden_1, hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([hidden_2, pred_class]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'b1' : tf.Variable(tf.random_normal([hidden_1])),\n",
    "    'b2' : tf.Variable(tf.random_normal([hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([pred_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_model(x):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), bias['b1'])\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), bias['b2'])\n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights['out']), bias['out'])\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = neural_model(x_)\n",
    "\n",
    "\n",
    "loss_ = tf.nn.softmax_cross_entropy_with_logits(labels=train_y, logits=logistic)\n",
    "optimize_ = tf.train.AdamOptimizer(0.001).minimize(loss_)\n",
    "corr_pred_ = tf.equal(tf.argmax(logistic,axis=1), tf.argmax(y_, axis=1))\n",
    "acc_ = tf.reduce_mean(tf.cast(corr_pred_, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 18)\n",
      "(418, 2)\n",
      "(891, 18)\n",
      "(891, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(test_x))\n",
    "print(np.shape(test_y))\n",
    "\n",
    "print(np.shape(train_x))\n",
    "print(np.shape(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINNING: Epoch 0 accuracy None\n",
      "Epoch 0 accuracy 0.6244019269943237\n",
      "TRAINNING: Epoch 1 accuracy None\n",
      "TRAINNING: Epoch 2 accuracy None\n",
      "TRAINNING: Epoch 3 accuracy None\n",
      "TRAINNING: Epoch 4 accuracy None\n",
      "TRAINNING: Epoch 5 accuracy None\n",
      "TRAINNING: Epoch 6 accuracy None\n",
      "TRAINNING: Epoch 7 accuracy None\n",
      "TRAINNING: Epoch 8 accuracy None\n",
      "TRAINNING: Epoch 9 accuracy None\n",
      "TRAINNING: Epoch 10 accuracy None\n",
      "TRAINNING: Epoch 11 accuracy None\n",
      "TRAINNING: Epoch 12 accuracy None\n",
      "TRAINNING: Epoch 13 accuracy None\n",
      "TRAINNING: Epoch 14 accuracy None\n",
      "TRAINNING: Epoch 15 accuracy None\n",
      "TRAINNING: Epoch 16 accuracy None\n",
      "TRAINNING: Epoch 17 accuracy None\n",
      "TRAINNING: Epoch 18 accuracy None\n",
      "TRAINNING: Epoch 19 accuracy None\n",
      "TRAINNING: Epoch 20 accuracy None\n",
      "TRAINNING: Epoch 21 accuracy None\n",
      "TRAINNING: Epoch 22 accuracy None\n",
      "TRAINNING: Epoch 23 accuracy None\n",
      "TRAINNING: Epoch 24 accuracy None\n",
      "TRAINNING: Epoch 25 accuracy None\n",
      "TRAINNING: Epoch 26 accuracy None\n",
      "TRAINNING: Epoch 27 accuracy None\n",
      "TRAINNING: Epoch 28 accuracy None\n",
      "TRAINNING: Epoch 29 accuracy None\n",
      "TRAINNING: Epoch 30 accuracy None\n",
      "TRAINNING: Epoch 31 accuracy None\n",
      "TRAINNING: Epoch 32 accuracy None\n",
      "TRAINNING: Epoch 33 accuracy None\n",
      "TRAINNING: Epoch 34 accuracy None\n",
      "TRAINNING: Epoch 35 accuracy None\n",
      "TRAINNING: Epoch 36 accuracy None\n",
      "TRAINNING: Epoch 37 accuracy None\n",
      "TRAINNING: Epoch 38 accuracy None\n",
      "TRAINNING: Epoch 39 accuracy None\n",
      "TRAINNING: Epoch 40 accuracy None\n",
      "TRAINNING: Epoch 41 accuracy None\n",
      "TRAINNING: Epoch 42 accuracy None\n",
      "TRAINNING: Epoch 43 accuracy None\n",
      "TRAINNING: Epoch 44 accuracy None\n",
      "TRAINNING: Epoch 45 accuracy None\n",
      "TRAINNING: Epoch 46 accuracy None\n",
      "TRAINNING: Epoch 47 accuracy None\n",
      "TRAINNING: Epoch 48 accuracy None\n",
      "TRAINNING: Epoch 49 accuracy None\n",
      "TRAINNING: Epoch 50 accuracy None\n",
      "Epoch 50 accuracy 0.6483253836631775\n",
      "TRAINNING: Epoch 51 accuracy None\n",
      "TRAINNING: Epoch 52 accuracy None\n",
      "TRAINNING: Epoch 53 accuracy None\n",
      "TRAINNING: Epoch 54 accuracy None\n",
      "TRAINNING: Epoch 55 accuracy None\n",
      "TRAINNING: Epoch 56 accuracy None\n",
      "TRAINNING: Epoch 57 accuracy None\n",
      "TRAINNING: Epoch 58 accuracy None\n",
      "TRAINNING: Epoch 59 accuracy None\n",
      "TRAINNING: Epoch 60 accuracy None\n",
      "TRAINNING: Epoch 61 accuracy None\n",
      "TRAINNING: Epoch 62 accuracy None\n",
      "TRAINNING: Epoch 63 accuracy None\n",
      "TRAINNING: Epoch 64 accuracy None\n",
      "TRAINNING: Epoch 65 accuracy None\n",
      "TRAINNING: Epoch 66 accuracy None\n",
      "TRAINNING: Epoch 67 accuracy None\n",
      "TRAINNING: Epoch 68 accuracy None\n",
      "TRAINNING: Epoch 69 accuracy None\n",
      "TRAINNING: Epoch 70 accuracy None\n",
      "TRAINNING: Epoch 71 accuracy None\n",
      "TRAINNING: Epoch 72 accuracy None\n",
      "TRAINNING: Epoch 73 accuracy None\n",
      "TRAINNING: Epoch 74 accuracy None\n",
      "TRAINNING: Epoch 75 accuracy None\n",
      "TRAINNING: Epoch 76 accuracy None\n",
      "TRAINNING: Epoch 77 accuracy None\n",
      "TRAINNING: Epoch 78 accuracy None\n",
      "TRAINNING: Epoch 79 accuracy None\n",
      "TRAINNING: Epoch 80 accuracy None\n",
      "TRAINNING: Epoch 81 accuracy None\n",
      "TRAINNING: Epoch 82 accuracy None\n",
      "TRAINNING: Epoch 83 accuracy None\n",
      "TRAINNING: Epoch 84 accuracy None\n",
      "TRAINNING: Epoch 85 accuracy None\n",
      "TRAINNING: Epoch 86 accuracy None\n",
      "TRAINNING: Epoch 87 accuracy None\n",
      "TRAINNING: Epoch 88 accuracy None\n",
      "TRAINNING: Epoch 89 accuracy None\n",
      "TRAINNING: Epoch 90 accuracy None\n",
      "TRAINNING: Epoch 91 accuracy None\n",
      "TRAINNING: Epoch 92 accuracy None\n",
      "TRAINNING: Epoch 93 accuracy None\n",
      "TRAINNING: Epoch 94 accuracy None\n",
      "TRAINNING: Epoch 95 accuracy None\n",
      "TRAINNING: Epoch 96 accuracy None\n",
      "TRAINNING: Epoch 97 accuracy None\n",
      "TRAINNING: Epoch 98 accuracy None\n",
      "TRAINNING: Epoch 99 accuracy None\n",
      "TRAINNING: Epoch 100 accuracy None\n",
      "Epoch 100 accuracy 0.7535884976387024\n",
      "TRAINNING: Epoch 101 accuracy None\n",
      "TRAINNING: Epoch 102 accuracy None\n",
      "TRAINNING: Epoch 103 accuracy None\n",
      "TRAINNING: Epoch 104 accuracy None\n",
      "TRAINNING: Epoch 105 accuracy None\n",
      "TRAINNING: Epoch 106 accuracy None\n",
      "TRAINNING: Epoch 107 accuracy None\n",
      "TRAINNING: Epoch 108 accuracy None\n",
      "TRAINNING: Epoch 109 accuracy None\n",
      "TRAINNING: Epoch 110 accuracy None\n",
      "TRAINNING: Epoch 111 accuracy None\n",
      "TRAINNING: Epoch 112 accuracy None\n",
      "TRAINNING: Epoch 113 accuracy None\n",
      "TRAINNING: Epoch 114 accuracy None\n",
      "TRAINNING: Epoch 115 accuracy None\n",
      "TRAINNING: Epoch 116 accuracy None\n",
      "TRAINNING: Epoch 117 accuracy None\n",
      "TRAINNING: Epoch 118 accuracy None\n",
      "TRAINNING: Epoch 119 accuracy None\n",
      "TRAINNING: Epoch 120 accuracy None\n",
      "TRAINNING: Epoch 121 accuracy None\n",
      "TRAINNING: Epoch 122 accuracy None\n",
      "TRAINNING: Epoch 123 accuracy None\n",
      "TRAINNING: Epoch 124 accuracy None\n",
      "TRAINNING: Epoch 125 accuracy None\n",
      "TRAINNING: Epoch 126 accuracy None\n",
      "TRAINNING: Epoch 127 accuracy None\n",
      "TRAINNING: Epoch 128 accuracy None\n",
      "TRAINNING: Epoch 129 accuracy None\n",
      "TRAINNING: Epoch 130 accuracy None\n",
      "TRAINNING: Epoch 131 accuracy None\n",
      "TRAINNING: Epoch 132 accuracy None\n",
      "TRAINNING: Epoch 133 accuracy None\n",
      "TRAINNING: Epoch 134 accuracy None\n",
      "TRAINNING: Epoch 135 accuracy None\n",
      "TRAINNING: Epoch 136 accuracy None\n",
      "TRAINNING: Epoch 137 accuracy None\n",
      "TRAINNING: Epoch 138 accuracy None\n",
      "TRAINNING: Epoch 139 accuracy None\n",
      "TRAINNING: Epoch 140 accuracy None\n",
      "TRAINNING: Epoch 141 accuracy None\n",
      "TRAINNING: Epoch 142 accuracy None\n",
      "TRAINNING: Epoch 143 accuracy None\n",
      "TRAINNING: Epoch 144 accuracy None\n",
      "TRAINNING: Epoch 145 accuracy None\n",
      "TRAINNING: Epoch 146 accuracy None\n",
      "TRAINNING: Epoch 147 accuracy None\n",
      "TRAINNING: Epoch 148 accuracy None\n",
      "TRAINNING: Epoch 149 accuracy None\n",
      "TRAINNING: Epoch 150 accuracy None\n",
      "Epoch 150 accuracy 0.8779904246330261\n",
      "TRAINNING: Epoch 151 accuracy None\n",
      "TRAINNING: Epoch 152 accuracy None\n",
      "TRAINNING: Epoch 153 accuracy None\n",
      "TRAINNING: Epoch 154 accuracy None\n",
      "TRAINNING: Epoch 155 accuracy None\n",
      "TRAINNING: Epoch 156 accuracy None\n",
      "TRAINNING: Epoch 157 accuracy None\n",
      "TRAINNING: Epoch 158 accuracy None\n",
      "TRAINNING: Epoch 159 accuracy None\n",
      "TRAINNING: Epoch 160 accuracy None\n",
      "TRAINNING: Epoch 161 accuracy None\n",
      "TRAINNING: Epoch 162 accuracy None\n",
      "TRAINNING: Epoch 163 accuracy None\n",
      "TRAINNING: Epoch 164 accuracy None\n",
      "TRAINNING: Epoch 165 accuracy None\n",
      "TRAINNING: Epoch 166 accuracy None\n",
      "TRAINNING: Epoch 167 accuracy None\n",
      "TRAINNING: Epoch 168 accuracy None\n",
      "TRAINNING: Epoch 169 accuracy None\n",
      "TRAINNING: Epoch 170 accuracy None\n",
      "TRAINNING: Epoch 171 accuracy None\n",
      "TRAINNING: Epoch 172 accuracy None\n",
      "TRAINNING: Epoch 173 accuracy None\n",
      "TRAINNING: Epoch 174 accuracy None\n",
      "TRAINNING: Epoch 175 accuracy None\n",
      "TRAINNING: Epoch 176 accuracy None\n",
      "TRAINNING: Epoch 177 accuracy None\n",
      "TRAINNING: Epoch 178 accuracy None\n",
      "TRAINNING: Epoch 179 accuracy None\n",
      "TRAINNING: Epoch 180 accuracy None\n",
      "TRAINNING: Epoch 181 accuracy None\n",
      "TRAINNING: Epoch 182 accuracy None\n",
      "TRAINNING: Epoch 183 accuracy None\n",
      "TRAINNING: Epoch 184 accuracy None\n",
      "TRAINNING: Epoch 185 accuracy None\n",
      "TRAINNING: Epoch 186 accuracy None\n",
      "TRAINNING: Epoch 187 accuracy None\n",
      "TRAINNING: Epoch 188 accuracy None\n",
      "TRAINNING: Epoch 189 accuracy None\n",
      "TRAINNING: Epoch 190 accuracy None\n",
      "TRAINNING: Epoch 191 accuracy None\n",
      "TRAINNING: Epoch 192 accuracy None\n",
      "TRAINNING: Epoch 193 accuracy None\n",
      "TRAINNING: Epoch 194 accuracy None\n",
      "TRAINNING: Epoch 195 accuracy None\n",
      "TRAINNING: Epoch 196 accuracy None\n",
      "TRAINNING: Epoch 197 accuracy None\n",
      "TRAINNING: Epoch 198 accuracy None\n",
      "TRAINNING: Epoch 199 accuracy None\n",
      "TRAINNING: Epoch 200 accuracy None\n",
      "Epoch 200 accuracy 0.4665071666240692\n",
      "TRAINNING: Epoch 201 accuracy None\n",
      "TRAINNING: Epoch 202 accuracy None\n",
      "TRAINNING: Epoch 203 accuracy None\n",
      "TRAINNING: Epoch 204 accuracy None\n",
      "TRAINNING: Epoch 205 accuracy None\n",
      "TRAINNING: Epoch 206 accuracy None\n",
      "TRAINNING: Epoch 207 accuracy None\n",
      "TRAINNING: Epoch 208 accuracy None\n",
      "TRAINNING: Epoch 209 accuracy None\n",
      "TRAINNING: Epoch 210 accuracy None\n",
      "TRAINNING: Epoch 211 accuracy None\n",
      "TRAINNING: Epoch 212 accuracy None\n",
      "TRAINNING: Epoch 213 accuracy None\n",
      "TRAINNING: Epoch 214 accuracy None\n",
      "TRAINNING: Epoch 215 accuracy None\n",
      "TRAINNING: Epoch 216 accuracy None\n",
      "TRAINNING: Epoch 217 accuracy None\n",
      "TRAINNING: Epoch 218 accuracy None\n",
      "TRAINNING: Epoch 219 accuracy None\n",
      "TRAINNING: Epoch 220 accuracy None\n",
      "TRAINNING: Epoch 221 accuracy None\n",
      "TRAINNING: Epoch 222 accuracy None\n",
      "TRAINNING: Epoch 223 accuracy None\n",
      "TRAINNING: Epoch 224 accuracy None\n",
      "TRAINNING: Epoch 225 accuracy None\n",
      "TRAINNING: Epoch 226 accuracy None\n",
      "TRAINNING: Epoch 227 accuracy None\n",
      "TRAINNING: Epoch 228 accuracy None\n",
      "TRAINNING: Epoch 229 accuracy None\n",
      "TRAINNING: Epoch 230 accuracy None\n",
      "TRAINNING: Epoch 231 accuracy None\n",
      "TRAINNING: Epoch 232 accuracy None\n",
      "TRAINNING: Epoch 233 accuracy None\n",
      "TRAINNING: Epoch 234 accuracy None\n",
      "TRAINNING: Epoch 235 accuracy None\n",
      "TRAINNING: Epoch 236 accuracy None\n",
      "TRAINNING: Epoch 237 accuracy None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINNING: Epoch 238 accuracy None\n",
      "TRAINNING: Epoch 239 accuracy None\n",
      "TRAINNING: Epoch 240 accuracy None\n",
      "TRAINNING: Epoch 241 accuracy None\n",
      "TRAINNING: Epoch 242 accuracy None\n",
      "TRAINNING: Epoch 243 accuracy None\n",
      "TRAINNING: Epoch 244 accuracy None\n",
      "TRAINNING: Epoch 245 accuracy None\n",
      "TRAINNING: Epoch 246 accuracy None\n",
      "TRAINNING: Epoch 247 accuracy None\n",
      "TRAINNING: Epoch 248 accuracy None\n",
      "TRAINNING: Epoch 249 accuracy None\n",
      "TRAINNING: Epoch 250 accuracy None\n",
      "Epoch 250 accuracy 0.7846890091896057\n",
      "TRAINNING: Epoch 251 accuracy None\n",
      "TRAINNING: Epoch 252 accuracy None\n",
      "TRAINNING: Epoch 253 accuracy None\n",
      "TRAINNING: Epoch 254 accuracy None\n",
      "TRAINNING: Epoch 255 accuracy None\n",
      "TRAINNING: Epoch 256 accuracy None\n",
      "TRAINNING: Epoch 257 accuracy None\n",
      "TRAINNING: Epoch 258 accuracy None\n",
      "TRAINNING: Epoch 259 accuracy None\n",
      "TRAINNING: Epoch 260 accuracy None\n",
      "TRAINNING: Epoch 261 accuracy None\n",
      "TRAINNING: Epoch 262 accuracy None\n",
      "TRAINNING: Epoch 263 accuracy None\n",
      "TRAINNING: Epoch 264 accuracy None\n",
      "TRAINNING: Epoch 265 accuracy None\n",
      "TRAINNING: Epoch 266 accuracy None\n",
      "TRAINNING: Epoch 267 accuracy None\n",
      "TRAINNING: Epoch 268 accuracy None\n",
      "TRAINNING: Epoch 269 accuracy None\n",
      "TRAINNING: Epoch 270 accuracy None\n",
      "TRAINNING: Epoch 271 accuracy None\n",
      "TRAINNING: Epoch 272 accuracy None\n",
      "TRAINNING: Epoch 273 accuracy None\n",
      "TRAINNING: Epoch 274 accuracy None\n",
      "TRAINNING: Epoch 275 accuracy None\n",
      "TRAINNING: Epoch 276 accuracy None\n",
      "TRAINNING: Epoch 277 accuracy None\n",
      "TRAINNING: Epoch 278 accuracy None\n",
      "TRAINNING: Epoch 279 accuracy None\n",
      "TRAINNING: Epoch 280 accuracy None\n",
      "TRAINNING: Epoch 281 accuracy None\n",
      "TRAINNING: Epoch 282 accuracy None\n",
      "TRAINNING: Epoch 283 accuracy None\n",
      "TRAINNING: Epoch 284 accuracy None\n",
      "TRAINNING: Epoch 285 accuracy None\n",
      "TRAINNING: Epoch 286 accuracy None\n",
      "TRAINNING: Epoch 287 accuracy None\n",
      "TRAINNING: Epoch 288 accuracy None\n",
      "TRAINNING: Epoch 289 accuracy None\n",
      "TRAINNING: Epoch 290 accuracy None\n",
      "TRAINNING: Epoch 291 accuracy None\n",
      "TRAINNING: Epoch 292 accuracy None\n",
      "TRAINNING: Epoch 293 accuracy None\n",
      "TRAINNING: Epoch 294 accuracy None\n",
      "TRAINNING: Epoch 295 accuracy None\n",
      "TRAINNING: Epoch 296 accuracy None\n",
      "TRAINNING: Epoch 297 accuracy None\n",
      "TRAINNING: Epoch 298 accuracy None\n",
      "TRAINNING: Epoch 299 accuracy None\n",
      "TRAINNING: Epoch 300 accuracy None\n",
      "Epoch 300 accuracy 0.6985645890235901\n",
      "TRAINNING: Epoch 301 accuracy None\n",
      "TRAINNING: Epoch 302 accuracy None\n",
      "TRAINNING: Epoch 303 accuracy None\n",
      "TRAINNING: Epoch 304 accuracy None\n",
      "TRAINNING: Epoch 305 accuracy None\n",
      "TRAINNING: Epoch 306 accuracy None\n",
      "TRAINNING: Epoch 307 accuracy None\n",
      "TRAINNING: Epoch 308 accuracy None\n",
      "TRAINNING: Epoch 309 accuracy None\n",
      "TRAINNING: Epoch 310 accuracy None\n",
      "TRAINNING: Epoch 311 accuracy None\n",
      "TRAINNING: Epoch 312 accuracy None\n",
      "TRAINNING: Epoch 313 accuracy None\n",
      "TRAINNING: Epoch 314 accuracy None\n",
      "TRAINNING: Epoch 315 accuracy None\n",
      "TRAINNING: Epoch 316 accuracy None\n",
      "TRAINNING: Epoch 317 accuracy None\n",
      "TRAINNING: Epoch 318 accuracy None\n",
      "TRAINNING: Epoch 319 accuracy None\n",
      "TRAINNING: Epoch 320 accuracy None\n",
      "TRAINNING: Epoch 321 accuracy None\n",
      "TRAINNING: Epoch 322 accuracy None\n",
      "TRAINNING: Epoch 323 accuracy None\n",
      "TRAINNING: Epoch 324 accuracy None\n",
      "TRAINNING: Epoch 325 accuracy None\n",
      "TRAINNING: Epoch 326 accuracy None\n",
      "TRAINNING: Epoch 327 accuracy None\n",
      "TRAINNING: Epoch 328 accuracy None\n",
      "TRAINNING: Epoch 329 accuracy None\n",
      "TRAINNING: Epoch 330 accuracy None\n",
      "TRAINNING: Epoch 331 accuracy None\n",
      "TRAINNING: Epoch 332 accuracy None\n",
      "TRAINNING: Epoch 333 accuracy None\n",
      "TRAINNING: Epoch 334 accuracy None\n",
      "TRAINNING: Epoch 335 accuracy None\n",
      "TRAINNING: Epoch 336 accuracy None\n",
      "TRAINNING: Epoch 337 accuracy None\n",
      "TRAINNING: Epoch 338 accuracy None\n",
      "TRAINNING: Epoch 339 accuracy None\n",
      "TRAINNING: Epoch 340 accuracy None\n",
      "TRAINNING: Epoch 341 accuracy None\n",
      "TRAINNING: Epoch 342 accuracy None\n",
      "TRAINNING: Epoch 343 accuracy None\n",
      "TRAINNING: Epoch 344 accuracy None\n",
      "TRAINNING: Epoch 345 accuracy None\n",
      "TRAINNING: Epoch 346 accuracy None\n",
      "TRAINNING: Epoch 347 accuracy None\n",
      "TRAINNING: Epoch 348 accuracy None\n",
      "TRAINNING: Epoch 349 accuracy None\n",
      "TRAINNING: Epoch 350 accuracy None\n",
      "Epoch 350 accuracy 0.89952152967453\n",
      "TRAINNING: Epoch 351 accuracy None\n",
      "TRAINNING: Epoch 352 accuracy None\n",
      "TRAINNING: Epoch 353 accuracy None\n",
      "TRAINNING: Epoch 354 accuracy None\n",
      "TRAINNING: Epoch 355 accuracy None\n",
      "TRAINNING: Epoch 356 accuracy None\n",
      "TRAINNING: Epoch 357 accuracy None\n",
      "TRAINNING: Epoch 358 accuracy None\n",
      "TRAINNING: Epoch 359 accuracy None\n",
      "TRAINNING: Epoch 360 accuracy None\n",
      "TRAINNING: Epoch 361 accuracy None\n",
      "TRAINNING: Epoch 362 accuracy None\n",
      "TRAINNING: Epoch 363 accuracy None\n",
      "TRAINNING: Epoch 364 accuracy None\n",
      "TRAINNING: Epoch 365 accuracy None\n",
      "TRAINNING: Epoch 366 accuracy None\n",
      "TRAINNING: Epoch 367 accuracy None\n",
      "TRAINNING: Epoch 368 accuracy None\n",
      "TRAINNING: Epoch 369 accuracy None\n",
      "TRAINNING: Epoch 370 accuracy None\n",
      "TRAINNING: Epoch 371 accuracy None\n",
      "TRAINNING: Epoch 372 accuracy None\n",
      "TRAINNING: Epoch 373 accuracy None\n",
      "TRAINNING: Epoch 374 accuracy None\n",
      "TRAINNING: Epoch 375 accuracy None\n",
      "TRAINNING: Epoch 376 accuracy None\n",
      "TRAINNING: Epoch 377 accuracy None\n",
      "TRAINNING: Epoch 378 accuracy None\n",
      "TRAINNING: Epoch 379 accuracy None\n",
      "TRAINNING: Epoch 380 accuracy None\n",
      "TRAINNING: Epoch 381 accuracy None\n",
      "TRAINNING: Epoch 382 accuracy None\n",
      "TRAINNING: Epoch 383 accuracy None\n",
      "TRAINNING: Epoch 384 accuracy None\n",
      "TRAINNING: Epoch 385 accuracy None\n",
      "TRAINNING: Epoch 386 accuracy None\n",
      "TRAINNING: Epoch 387 accuracy None\n",
      "TRAINNING: Epoch 388 accuracy None\n",
      "TRAINNING: Epoch 389 accuracy None\n",
      "TRAINNING: Epoch 390 accuracy None\n",
      "TRAINNING: Epoch 391 accuracy None\n",
      "TRAINNING: Epoch 392 accuracy None\n",
      "TRAINNING: Epoch 393 accuracy None\n",
      "TRAINNING: Epoch 394 accuracy None\n",
      "TRAINNING: Epoch 395 accuracy None\n",
      "TRAINNING: Epoch 396 accuracy None\n",
      "TRAINNING: Epoch 397 accuracy None\n",
      "TRAINNING: Epoch 398 accuracy None\n",
      "TRAINNING: Epoch 399 accuracy None\n",
      "TRAINNING: Epoch 400 accuracy None\n",
      "Epoch 400 accuracy 0.7727272510528564\n",
      "TRAINNING: Epoch 401 accuracy None\n",
      "TRAINNING: Epoch 402 accuracy None\n",
      "TRAINNING: Epoch 403 accuracy None\n",
      "TRAINNING: Epoch 404 accuracy None\n",
      "TRAINNING: Epoch 405 accuracy None\n",
      "TRAINNING: Epoch 406 accuracy None\n",
      "TRAINNING: Epoch 407 accuracy None\n",
      "TRAINNING: Epoch 408 accuracy None\n",
      "TRAINNING: Epoch 409 accuracy None\n",
      "TRAINNING: Epoch 410 accuracy None\n",
      "TRAINNING: Epoch 411 accuracy None\n",
      "TRAINNING: Epoch 412 accuracy None\n",
      "TRAINNING: Epoch 413 accuracy None\n",
      "TRAINNING: Epoch 414 accuracy None\n",
      "TRAINNING: Epoch 415 accuracy None\n",
      "TRAINNING: Epoch 416 accuracy None\n",
      "TRAINNING: Epoch 417 accuracy None\n",
      "TRAINNING: Epoch 418 accuracy None\n",
      "TRAINNING: Epoch 419 accuracy None\n",
      "TRAINNING: Epoch 420 accuracy None\n",
      "TRAINNING: Epoch 421 accuracy None\n",
      "TRAINNING: Epoch 422 accuracy None\n",
      "TRAINNING: Epoch 423 accuracy None\n",
      "TRAINNING: Epoch 424 accuracy None\n",
      "TRAINNING: Epoch 425 accuracy None\n",
      "TRAINNING: Epoch 426 accuracy None\n",
      "TRAINNING: Epoch 427 accuracy None\n",
      "TRAINNING: Epoch 428 accuracy None\n",
      "TRAINNING: Epoch 429 accuracy None\n",
      "TRAINNING: Epoch 430 accuracy None\n",
      "TRAINNING: Epoch 431 accuracy None\n",
      "TRAINNING: Epoch 432 accuracy None\n",
      "TRAINNING: Epoch 433 accuracy None\n",
      "TRAINNING: Epoch 434 accuracy None\n",
      "TRAINNING: Epoch 435 accuracy None\n",
      "TRAINNING: Epoch 436 accuracy None\n",
      "TRAINNING: Epoch 437 accuracy None\n",
      "TRAINNING: Epoch 438 accuracy None\n",
      "TRAINNING: Epoch 439 accuracy None\n",
      "TRAINNING: Epoch 440 accuracy None\n",
      "TRAINNING: Epoch 441 accuracy None\n",
      "TRAINNING: Epoch 442 accuracy None\n",
      "TRAINNING: Epoch 443 accuracy None\n",
      "TRAINNING: Epoch 444 accuracy None\n",
      "TRAINNING: Epoch 445 accuracy None\n",
      "TRAINNING: Epoch 446 accuracy None\n",
      "TRAINNING: Epoch 447 accuracy None\n",
      "TRAINNING: Epoch 448 accuracy None\n",
      "TRAINNING: Epoch 449 accuracy None\n",
      "TRAINNING: Epoch 450 accuracy None\n",
      "Epoch 450 accuracy 0.739234447479248\n",
      "TRAINNING: Epoch 451 accuracy None\n",
      "TRAINNING: Epoch 452 accuracy None\n",
      "TRAINNING: Epoch 453 accuracy None\n",
      "TRAINNING: Epoch 454 accuracy None\n",
      "TRAINNING: Epoch 455 accuracy None\n",
      "TRAINNING: Epoch 456 accuracy None\n",
      "TRAINNING: Epoch 457 accuracy None\n",
      "TRAINNING: Epoch 458 accuracy None\n",
      "TRAINNING: Epoch 459 accuracy None\n",
      "TRAINNING: Epoch 460 accuracy None\n",
      "TRAINNING: Epoch 461 accuracy None\n",
      "TRAINNING: Epoch 462 accuracy None\n",
      "TRAINNING: Epoch 463 accuracy None\n",
      "TRAINNING: Epoch 464 accuracy None\n",
      "TRAINNING: Epoch 465 accuracy None\n",
      "TRAINNING: Epoch 466 accuracy None\n",
      "TRAINNING: Epoch 467 accuracy None\n",
      "TRAINNING: Epoch 468 accuracy None\n",
      "TRAINNING: Epoch 469 accuracy None\n",
      "TRAINNING: Epoch 470 accuracy None\n",
      "TRAINNING: Epoch 471 accuracy None\n",
      "TRAINNING: Epoch 472 accuracy None\n",
      "TRAINNING: Epoch 473 accuracy None\n",
      "TRAINNING: Epoch 474 accuracy None\n",
      "TRAINNING: Epoch 475 accuracy None\n",
      "TRAINNING: Epoch 476 accuracy None\n",
      "TRAINNING: Epoch 477 accuracy None\n",
      "TRAINNING: Epoch 478 accuracy None\n",
      "TRAINNING: Epoch 479 accuracy None\n",
      "TRAINNING: Epoch 480 accuracy None\n",
      "TRAINNING: Epoch 481 accuracy None\n",
      "TRAINNING: Epoch 482 accuracy None\n",
      "TRAINNING: Epoch 483 accuracy None\n",
      "TRAINNING: Epoch 484 accuracy None\n",
      "TRAINNING: Epoch 485 accuracy None\n",
      "TRAINNING: Epoch 486 accuracy None\n",
      "TRAINNING: Epoch 487 accuracy None\n",
      "TRAINNING: Epoch 488 accuracy None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINNING: Epoch 489 accuracy None\n",
      "TRAINNING: Epoch 490 accuracy None\n",
      "TRAINNING: Epoch 491 accuracy None\n",
      "TRAINNING: Epoch 492 accuracy None\n",
      "TRAINNING: Epoch 493 accuracy None\n",
      "TRAINNING: Epoch 494 accuracy None\n",
      "TRAINNING: Epoch 495 accuracy None\n",
      "TRAINNING: Epoch 496 accuracy None\n",
      "TRAINNING: Epoch 497 accuracy None\n",
      "TRAINNING: Epoch 498 accuracy None\n",
      "TRAINNING: Epoch 499 accuracy None\n",
      "TRAINNING: Epoch 500 accuracy None\n",
      "Epoch 500 accuracy 0.7177033424377441\n",
      "TRAINNING: Epoch 501 accuracy None\n",
      "TRAINNING: Epoch 502 accuracy None\n",
      "TRAINNING: Epoch 503 accuracy None\n",
      "TRAINNING: Epoch 504 accuracy None\n",
      "TRAINNING: Epoch 505 accuracy None\n",
      "TRAINNING: Epoch 506 accuracy None\n",
      "TRAINNING: Epoch 507 accuracy None\n",
      "TRAINNING: Epoch 508 accuracy None\n",
      "TRAINNING: Epoch 509 accuracy None\n",
      "TRAINNING: Epoch 510 accuracy None\n",
      "TRAINNING: Epoch 511 accuracy None\n",
      "TRAINNING: Epoch 512 accuracy None\n",
      "TRAINNING: Epoch 513 accuracy None\n",
      "TRAINNING: Epoch 514 accuracy None\n",
      "TRAINNING: Epoch 515 accuracy None\n",
      "TRAINNING: Epoch 516 accuracy None\n",
      "TRAINNING: Epoch 517 accuracy None\n",
      "TRAINNING: Epoch 518 accuracy None\n",
      "TRAINNING: Epoch 519 accuracy None\n",
      "TRAINNING: Epoch 520 accuracy None\n",
      "TRAINNING: Epoch 521 accuracy None\n",
      "TRAINNING: Epoch 522 accuracy None\n",
      "TRAINNING: Epoch 523 accuracy None\n",
      "TRAINNING: Epoch 524 accuracy None\n",
      "TRAINNING: Epoch 525 accuracy None\n",
      "TRAINNING: Epoch 526 accuracy None\n",
      "TRAINNING: Epoch 527 accuracy None\n",
      "TRAINNING: Epoch 528 accuracy None\n",
      "TRAINNING: Epoch 529 accuracy None\n",
      "TRAINNING: Epoch 530 accuracy None\n",
      "TRAINNING: Epoch 531 accuracy None\n",
      "TRAINNING: Epoch 532 accuracy None\n",
      "TRAINNING: Epoch 533 accuracy None\n",
      "TRAINNING: Epoch 534 accuracy None\n",
      "TRAINNING: Epoch 535 accuracy None\n",
      "TRAINNING: Epoch 536 accuracy None\n",
      "TRAINNING: Epoch 537 accuracy None\n",
      "TRAINNING: Epoch 538 accuracy None\n",
      "TRAINNING: Epoch 539 accuracy None\n",
      "TRAINNING: Epoch 540 accuracy None\n",
      "TRAINNING: Epoch 541 accuracy None\n",
      "TRAINNING: Epoch 542 accuracy None\n",
      "TRAINNING: Epoch 543 accuracy None\n",
      "TRAINNING: Epoch 544 accuracy None\n",
      "TRAINNING: Epoch 545 accuracy None\n",
      "TRAINNING: Epoch 546 accuracy None\n",
      "TRAINNING: Epoch 547 accuracy None\n",
      "TRAINNING: Epoch 548 accuracy None\n",
      "TRAINNING: Epoch 549 accuracy None\n",
      "TRAINNING: Epoch 550 accuracy None\n",
      "Epoch 550 accuracy 0.8588516712188721\n",
      "TRAINNING: Epoch 551 accuracy None\n",
      "TRAINNING: Epoch 552 accuracy None\n",
      "TRAINNING: Epoch 553 accuracy None\n",
      "TRAINNING: Epoch 554 accuracy None\n",
      "TRAINNING: Epoch 555 accuracy None\n",
      "TRAINNING: Epoch 556 accuracy None\n",
      "TRAINNING: Epoch 557 accuracy None\n",
      "TRAINNING: Epoch 558 accuracy None\n",
      "TRAINNING: Epoch 559 accuracy None\n",
      "TRAINNING: Epoch 560 accuracy None\n",
      "TRAINNING: Epoch 561 accuracy None\n",
      "TRAINNING: Epoch 562 accuracy None\n",
      "TRAINNING: Epoch 563 accuracy None\n",
      "TRAINNING: Epoch 564 accuracy None\n",
      "TRAINNING: Epoch 565 accuracy None\n",
      "TRAINNING: Epoch 566 accuracy None\n",
      "TRAINNING: Epoch 567 accuracy None\n",
      "TRAINNING: Epoch 568 accuracy None\n",
      "TRAINNING: Epoch 569 accuracy None\n",
      "TRAINNING: Epoch 570 accuracy None\n",
      "TRAINNING: Epoch 571 accuracy None\n",
      "TRAINNING: Epoch 572 accuracy None\n",
      "TRAINNING: Epoch 573 accuracy None\n",
      "TRAINNING: Epoch 574 accuracy None\n",
      "TRAINNING: Epoch 575 accuracy None\n",
      "TRAINNING: Epoch 576 accuracy None\n",
      "TRAINNING: Epoch 577 accuracy None\n",
      "TRAINNING: Epoch 578 accuracy None\n",
      "TRAINNING: Epoch 579 accuracy None\n",
      "TRAINNING: Epoch 580 accuracy None\n",
      "TRAINNING: Epoch 581 accuracy None\n",
      "TRAINNING: Epoch 582 accuracy None\n",
      "TRAINNING: Epoch 583 accuracy None\n",
      "TRAINNING: Epoch 584 accuracy None\n",
      "TRAINNING: Epoch 585 accuracy None\n",
      "TRAINNING: Epoch 586 accuracy None\n",
      "TRAINNING: Epoch 587 accuracy None\n",
      "TRAINNING: Epoch 588 accuracy None\n",
      "TRAINNING: Epoch 589 accuracy None\n",
      "TRAINNING: Epoch 590 accuracy None\n",
      "TRAINNING: Epoch 591 accuracy None\n",
      "TRAINNING: Epoch 592 accuracy None\n",
      "TRAINNING: Epoch 593 accuracy None\n",
      "TRAINNING: Epoch 594 accuracy None\n",
      "TRAINNING: Epoch 595 accuracy None\n",
      "TRAINNING: Epoch 596 accuracy None\n",
      "TRAINNING: Epoch 597 accuracy None\n",
      "TRAINNING: Epoch 598 accuracy None\n",
      "TRAINNING: Epoch 599 accuracy None\n",
      "TRAINNING: Epoch 600 accuracy None\n",
      "Epoch 600 accuracy 0.6674641370773315\n",
      "TRAINNING: Epoch 601 accuracy None\n",
      "TRAINNING: Epoch 602 accuracy None\n",
      "TRAINNING: Epoch 603 accuracy None\n",
      "TRAINNING: Epoch 604 accuracy None\n",
      "TRAINNING: Epoch 605 accuracy None\n",
      "TRAINNING: Epoch 606 accuracy None\n",
      "TRAINNING: Epoch 607 accuracy None\n",
      "TRAINNING: Epoch 608 accuracy None\n",
      "TRAINNING: Epoch 609 accuracy None\n",
      "TRAINNING: Epoch 610 accuracy None\n",
      "TRAINNING: Epoch 611 accuracy None\n",
      "TRAINNING: Epoch 612 accuracy None\n",
      "TRAINNING: Epoch 613 accuracy None\n",
      "TRAINNING: Epoch 614 accuracy None\n",
      "TRAINNING: Epoch 615 accuracy None\n",
      "TRAINNING: Epoch 616 accuracy None\n",
      "TRAINNING: Epoch 617 accuracy None\n",
      "TRAINNING: Epoch 618 accuracy None\n",
      "TRAINNING: Epoch 619 accuracy None\n",
      "TRAINNING: Epoch 620 accuracy None\n",
      "TRAINNING: Epoch 621 accuracy None\n",
      "TRAINNING: Epoch 622 accuracy None\n",
      "TRAINNING: Epoch 623 accuracy None\n",
      "TRAINNING: Epoch 624 accuracy None\n",
      "TRAINNING: Epoch 625 accuracy None\n",
      "TRAINNING: Epoch 626 accuracy None\n",
      "TRAINNING: Epoch 627 accuracy None\n",
      "TRAINNING: Epoch 628 accuracy None\n",
      "TRAINNING: Epoch 629 accuracy None\n",
      "TRAINNING: Epoch 630 accuracy None\n",
      "TRAINNING: Epoch 631 accuracy None\n",
      "TRAINNING: Epoch 632 accuracy None\n",
      "TRAINNING: Epoch 633 accuracy None\n",
      "TRAINNING: Epoch 634 accuracy None\n",
      "TRAINNING: Epoch 635 accuracy None\n",
      "TRAINNING: Epoch 636 accuracy None\n",
      "TRAINNING: Epoch 637 accuracy None\n",
      "TRAINNING: Epoch 638 accuracy None\n",
      "TRAINNING: Epoch 639 accuracy None\n",
      "TRAINNING: Epoch 640 accuracy None\n",
      "TRAINNING: Epoch 641 accuracy None\n",
      "TRAINNING: Epoch 642 accuracy None\n",
      "TRAINNING: Epoch 643 accuracy None\n",
      "TRAINNING: Epoch 644 accuracy None\n",
      "TRAINNING: Epoch 645 accuracy None\n",
      "TRAINNING: Epoch 646 accuracy None\n",
      "TRAINNING: Epoch 647 accuracy None\n",
      "TRAINNING: Epoch 648 accuracy None\n",
      "TRAINNING: Epoch 649 accuracy None\n",
      "TRAINNING: Epoch 650 accuracy None\n",
      "Epoch 650 accuracy 0.8253588676452637\n",
      "TRAINNING: Epoch 651 accuracy None\n",
      "TRAINNING: Epoch 652 accuracy None\n",
      "TRAINNING: Epoch 653 accuracy None\n",
      "TRAINNING: Epoch 654 accuracy None\n",
      "TRAINNING: Epoch 655 accuracy None\n",
      "TRAINNING: Epoch 656 accuracy None\n",
      "TRAINNING: Epoch 657 accuracy None\n",
      "TRAINNING: Epoch 658 accuracy None\n",
      "TRAINNING: Epoch 659 accuracy None\n",
      "TRAINNING: Epoch 660 accuracy None\n",
      "TRAINNING: Epoch 661 accuracy None\n",
      "TRAINNING: Epoch 662 accuracy None\n",
      "TRAINNING: Epoch 663 accuracy None\n",
      "TRAINNING: Epoch 664 accuracy None\n",
      "TRAINNING: Epoch 665 accuracy None\n",
      "TRAINNING: Epoch 666 accuracy None\n",
      "TRAINNING: Epoch 667 accuracy None\n",
      "TRAINNING: Epoch 668 accuracy None\n",
      "TRAINNING: Epoch 669 accuracy None\n",
      "TRAINNING: Epoch 670 accuracy None\n",
      "TRAINNING: Epoch 671 accuracy None\n",
      "TRAINNING: Epoch 672 accuracy None\n",
      "TRAINNING: Epoch 673 accuracy None\n",
      "TRAINNING: Epoch 674 accuracy None\n",
      "TRAINNING: Epoch 675 accuracy None\n",
      "TRAINNING: Epoch 676 accuracy None\n",
      "TRAINNING: Epoch 677 accuracy None\n",
      "TRAINNING: Epoch 678 accuracy None\n",
      "TRAINNING: Epoch 679 accuracy None\n",
      "TRAINNING: Epoch 680 accuracy None\n",
      "TRAINNING: Epoch 681 accuracy None\n",
      "TRAINNING: Epoch 682 accuracy None\n",
      "TRAINNING: Epoch 683 accuracy None\n",
      "TRAINNING: Epoch 684 accuracy None\n",
      "TRAINNING: Epoch 685 accuracy None\n",
      "TRAINNING: Epoch 686 accuracy None\n",
      "TRAINNING: Epoch 687 accuracy None\n",
      "TRAINNING: Epoch 688 accuracy None\n",
      "TRAINNING: Epoch 689 accuracy None\n",
      "TRAINNING: Epoch 690 accuracy None\n",
      "TRAINNING: Epoch 691 accuracy None\n",
      "TRAINNING: Epoch 692 accuracy None\n",
      "TRAINNING: Epoch 693 accuracy None\n",
      "TRAINNING: Epoch 694 accuracy None\n",
      "TRAINNING: Epoch 695 accuracy None\n",
      "TRAINNING: Epoch 696 accuracy None\n",
      "TRAINNING: Epoch 697 accuracy None\n",
      "TRAINNING: Epoch 698 accuracy None\n",
      "TRAINNING: Epoch 699 accuracy None\n",
      "TRAINNING: Epoch 700 accuracy None\n",
      "Epoch 700 accuracy 0.7488038539886475\n",
      "TRAINNING: Epoch 701 accuracy None\n",
      "TRAINNING: Epoch 702 accuracy None\n",
      "TRAINNING: Epoch 703 accuracy None\n",
      "TRAINNING: Epoch 704 accuracy None\n",
      "TRAINNING: Epoch 705 accuracy None\n",
      "TRAINNING: Epoch 706 accuracy None\n",
      "TRAINNING: Epoch 707 accuracy None\n",
      "TRAINNING: Epoch 708 accuracy None\n",
      "TRAINNING: Epoch 709 accuracy None\n",
      "TRAINNING: Epoch 710 accuracy None\n",
      "TRAINNING: Epoch 711 accuracy None\n",
      "TRAINNING: Epoch 712 accuracy None\n",
      "TRAINNING: Epoch 713 accuracy None\n",
      "TRAINNING: Epoch 714 accuracy None\n",
      "TRAINNING: Epoch 715 accuracy None\n",
      "TRAINNING: Epoch 716 accuracy None\n",
      "TRAINNING: Epoch 717 accuracy None\n",
      "TRAINNING: Epoch 718 accuracy None\n",
      "TRAINNING: Epoch 719 accuracy None\n",
      "TRAINNING: Epoch 720 accuracy None\n",
      "TRAINNING: Epoch 721 accuracy None\n",
      "TRAINNING: Epoch 722 accuracy None\n",
      "TRAINNING: Epoch 723 accuracy None\n",
      "TRAINNING: Epoch 724 accuracy None\n",
      "TRAINNING: Epoch 725 accuracy None\n",
      "TRAINNING: Epoch 726 accuracy None\n",
      "TRAINNING: Epoch 727 accuracy None\n",
      "TRAINNING: Epoch 728 accuracy None\n",
      "TRAINNING: Epoch 729 accuracy None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINNING: Epoch 730 accuracy None\n",
      "TRAINNING: Epoch 731 accuracy None\n",
      "TRAINNING: Epoch 732 accuracy None\n",
      "TRAINNING: Epoch 733 accuracy None\n",
      "TRAINNING: Epoch 734 accuracy None\n",
      "TRAINNING: Epoch 735 accuracy None\n",
      "TRAINNING: Epoch 736 accuracy None\n",
      "TRAINNING: Epoch 737 accuracy None\n",
      "TRAINNING: Epoch 738 accuracy None\n",
      "TRAINNING: Epoch 739 accuracy None\n",
      "TRAINNING: Epoch 740 accuracy None\n",
      "TRAINNING: Epoch 741 accuracy None\n",
      "TRAINNING: Epoch 742 accuracy None\n",
      "TRAINNING: Epoch 743 accuracy None\n",
      "TRAINNING: Epoch 744 accuracy None\n",
      "TRAINNING: Epoch 745 accuracy None\n",
      "TRAINNING: Epoch 746 accuracy None\n",
      "TRAINNING: Epoch 747 accuracy None\n",
      "TRAINNING: Epoch 748 accuracy None\n",
      "TRAINNING: Epoch 749 accuracy None\n",
      "TRAINNING: Epoch 750 accuracy None\n",
      "Epoch 750 accuracy 0.6578947305679321\n",
      "TRAINNING: Epoch 751 accuracy None\n",
      "TRAINNING: Epoch 752 accuracy None\n",
      "TRAINNING: Epoch 753 accuracy None\n",
      "TRAINNING: Epoch 754 accuracy None\n",
      "TRAINNING: Epoch 755 accuracy None\n",
      "TRAINNING: Epoch 756 accuracy None\n",
      "TRAINNING: Epoch 757 accuracy None\n",
      "TRAINNING: Epoch 758 accuracy None\n",
      "TRAINNING: Epoch 759 accuracy None\n",
      "TRAINNING: Epoch 760 accuracy None\n",
      "TRAINNING: Epoch 761 accuracy None\n",
      "TRAINNING: Epoch 762 accuracy None\n",
      "TRAINNING: Epoch 763 accuracy None\n",
      "TRAINNING: Epoch 764 accuracy None\n",
      "TRAINNING: Epoch 765 accuracy None\n",
      "TRAINNING: Epoch 766 accuracy None\n",
      "TRAINNING: Epoch 767 accuracy None\n",
      "TRAINNING: Epoch 768 accuracy None\n",
      "TRAINNING: Epoch 769 accuracy None\n",
      "TRAINNING: Epoch 770 accuracy None\n",
      "TRAINNING: Epoch 771 accuracy None\n",
      "TRAINNING: Epoch 772 accuracy None\n",
      "TRAINNING: Epoch 773 accuracy None\n",
      "TRAINNING: Epoch 774 accuracy None\n",
      "TRAINNING: Epoch 775 accuracy None\n",
      "TRAINNING: Epoch 776 accuracy None\n",
      "TRAINNING: Epoch 777 accuracy None\n",
      "TRAINNING: Epoch 778 accuracy None\n",
      "TRAINNING: Epoch 779 accuracy None\n",
      "TRAINNING: Epoch 780 accuracy None\n",
      "TRAINNING: Epoch 781 accuracy None\n",
      "TRAINNING: Epoch 782 accuracy None\n",
      "TRAINNING: Epoch 783 accuracy None\n",
      "TRAINNING: Epoch 784 accuracy None\n",
      "TRAINNING: Epoch 785 accuracy None\n",
      "TRAINNING: Epoch 786 accuracy None\n",
      "TRAINNING: Epoch 787 accuracy None\n",
      "TRAINNING: Epoch 788 accuracy None\n",
      "TRAINNING: Epoch 789 accuracy None\n",
      "TRAINNING: Epoch 790 accuracy None\n",
      "TRAINNING: Epoch 791 accuracy None\n",
      "TRAINNING: Epoch 792 accuracy None\n",
      "TRAINNING: Epoch 793 accuracy None\n",
      "TRAINNING: Epoch 794 accuracy None\n",
      "TRAINNING: Epoch 795 accuracy None\n",
      "TRAINNING: Epoch 796 accuracy None\n",
      "TRAINNING: Epoch 797 accuracy None\n",
      "TRAINNING: Epoch 798 accuracy None\n",
      "TRAINNING: Epoch 799 accuracy None\n",
      "TRAINNING: Epoch 800 accuracy None\n",
      "Epoch 800 accuracy 0.6889952421188354\n",
      "TRAINNING: Epoch 801 accuracy None\n",
      "TRAINNING: Epoch 802 accuracy None\n",
      "TRAINNING: Epoch 803 accuracy None\n",
      "TRAINNING: Epoch 804 accuracy None\n",
      "TRAINNING: Epoch 805 accuracy None\n",
      "TRAINNING: Epoch 806 accuracy None\n",
      "TRAINNING: Epoch 807 accuracy None\n",
      "TRAINNING: Epoch 808 accuracy None\n",
      "TRAINNING: Epoch 809 accuracy None\n",
      "TRAINNING: Epoch 810 accuracy None\n",
      "TRAINNING: Epoch 811 accuracy None\n",
      "TRAINNING: Epoch 812 accuracy None\n",
      "TRAINNING: Epoch 813 accuracy None\n",
      "TRAINNING: Epoch 814 accuracy None\n",
      "TRAINNING: Epoch 815 accuracy None\n",
      "TRAINNING: Epoch 816 accuracy None\n",
      "TRAINNING: Epoch 817 accuracy None\n",
      "TRAINNING: Epoch 818 accuracy None\n",
      "TRAINNING: Epoch 819 accuracy None\n",
      "TRAINNING: Epoch 820 accuracy None\n",
      "TRAINNING: Epoch 821 accuracy None\n",
      "TRAINNING: Epoch 822 accuracy None\n",
      "TRAINNING: Epoch 823 accuracy None\n",
      "TRAINNING: Epoch 824 accuracy None\n",
      "TRAINNING: Epoch 825 accuracy None\n",
      "TRAINNING: Epoch 826 accuracy None\n",
      "TRAINNING: Epoch 827 accuracy None\n",
      "TRAINNING: Epoch 828 accuracy None\n",
      "TRAINNING: Epoch 829 accuracy None\n",
      "TRAINNING: Epoch 830 accuracy None\n",
      "TRAINNING: Epoch 831 accuracy None\n",
      "TRAINNING: Epoch 832 accuracy None\n",
      "TRAINNING: Epoch 833 accuracy None\n",
      "TRAINNING: Epoch 834 accuracy None\n",
      "TRAINNING: Epoch 835 accuracy None\n",
      "TRAINNING: Epoch 836 accuracy None\n",
      "TRAINNING: Epoch 837 accuracy None\n",
      "TRAINNING: Epoch 838 accuracy None\n",
      "TRAINNING: Epoch 839 accuracy None\n",
      "TRAINNING: Epoch 840 accuracy None\n",
      "TRAINNING: Epoch 841 accuracy None\n",
      "TRAINNING: Epoch 842 accuracy None\n",
      "TRAINNING: Epoch 843 accuracy None\n",
      "TRAINNING: Epoch 844 accuracy None\n",
      "TRAINNING: Epoch 845 accuracy None\n",
      "TRAINNING: Epoch 846 accuracy None\n",
      "TRAINNING: Epoch 847 accuracy None\n",
      "TRAINNING: Epoch 848 accuracy None\n",
      "TRAINNING: Epoch 849 accuracy None\n",
      "TRAINNING: Epoch 850 accuracy None\n",
      "Epoch 850 accuracy 0.779904305934906\n",
      "TRAINNING: Epoch 851 accuracy None\n",
      "TRAINNING: Epoch 852 accuracy None\n",
      "TRAINNING: Epoch 853 accuracy None\n",
      "TRAINNING: Epoch 854 accuracy None\n",
      "TRAINNING: Epoch 855 accuracy None\n",
      "TRAINNING: Epoch 856 accuracy None\n",
      "TRAINNING: Epoch 857 accuracy None\n",
      "TRAINNING: Epoch 858 accuracy None\n",
      "TRAINNING: Epoch 859 accuracy None\n",
      "TRAINNING: Epoch 860 accuracy None\n",
      "TRAINNING: Epoch 861 accuracy None\n",
      "TRAINNING: Epoch 862 accuracy None\n",
      "TRAINNING: Epoch 863 accuracy None\n",
      "TRAINNING: Epoch 864 accuracy None\n",
      "TRAINNING: Epoch 865 accuracy None\n",
      "TRAINNING: Epoch 866 accuracy None\n",
      "TRAINNING: Epoch 867 accuracy None\n",
      "TRAINNING: Epoch 868 accuracy None\n",
      "TRAINNING: Epoch 869 accuracy None\n",
      "TRAINNING: Epoch 870 accuracy None\n",
      "TRAINNING: Epoch 871 accuracy None\n",
      "TRAINNING: Epoch 872 accuracy None\n",
      "TRAINNING: Epoch 873 accuracy None\n",
      "TRAINNING: Epoch 874 accuracy None\n",
      "TRAINNING: Epoch 875 accuracy None\n",
      "TRAINNING: Epoch 876 accuracy None\n",
      "TRAINNING: Epoch 877 accuracy None\n",
      "TRAINNING: Epoch 878 accuracy None\n",
      "TRAINNING: Epoch 879 accuracy None\n",
      "TRAINNING: Epoch 880 accuracy None\n",
      "TRAINNING: Epoch 881 accuracy None\n",
      "TRAINNING: Epoch 882 accuracy None\n",
      "TRAINNING: Epoch 883 accuracy None\n",
      "TRAINNING: Epoch 884 accuracy None\n",
      "TRAINNING: Epoch 885 accuracy None\n",
      "TRAINNING: Epoch 886 accuracy None\n",
      "TRAINNING: Epoch 887 accuracy None\n",
      "TRAINNING: Epoch 888 accuracy None\n",
      "TRAINNING: Epoch 889 accuracy None\n",
      "TRAINNING: Epoch 890 accuracy None\n",
      "TRAINNING: Epoch 891 accuracy None\n",
      "TRAINNING: Epoch 892 accuracy None\n",
      "TRAINNING: Epoch 893 accuracy None\n",
      "TRAINNING: Epoch 894 accuracy None\n",
      "TRAINNING: Epoch 895 accuracy None\n",
      "TRAINNING: Epoch 896 accuracy None\n",
      "TRAINNING: Epoch 897 accuracy None\n",
      "TRAINNING: Epoch 898 accuracy None\n",
      "TRAINNING: Epoch 899 accuracy None\n",
      "TRAINNING: Epoch 900 accuracy None\n",
      "Epoch 900 accuracy 0.9043062329292297\n",
      "TRAINNING: Epoch 901 accuracy None\n",
      "TRAINNING: Epoch 902 accuracy None\n",
      "TRAINNING: Epoch 903 accuracy None\n",
      "TRAINNING: Epoch 904 accuracy None\n",
      "TRAINNING: Epoch 905 accuracy None\n",
      "TRAINNING: Epoch 906 accuracy None\n",
      "TRAINNING: Epoch 907 accuracy None\n",
      "TRAINNING: Epoch 908 accuracy None\n",
      "TRAINNING: Epoch 909 accuracy None\n",
      "TRAINNING: Epoch 910 accuracy None\n",
      "TRAINNING: Epoch 911 accuracy None\n",
      "TRAINNING: Epoch 912 accuracy None\n",
      "TRAINNING: Epoch 913 accuracy None\n",
      "TRAINNING: Epoch 914 accuracy None\n",
      "TRAINNING: Epoch 915 accuracy None\n",
      "TRAINNING: Epoch 916 accuracy None\n",
      "TRAINNING: Epoch 917 accuracy None\n",
      "TRAINNING: Epoch 918 accuracy None\n",
      "TRAINNING: Epoch 919 accuracy None\n",
      "TRAINNING: Epoch 920 accuracy None\n",
      "TRAINNING: Epoch 921 accuracy None\n",
      "TRAINNING: Epoch 922 accuracy None\n",
      "TRAINNING: Epoch 923 accuracy None\n",
      "TRAINNING: Epoch 924 accuracy None\n",
      "TRAINNING: Epoch 925 accuracy None\n",
      "TRAINNING: Epoch 926 accuracy None\n",
      "TRAINNING: Epoch 927 accuracy None\n",
      "TRAINNING: Epoch 928 accuracy None\n",
      "TRAINNING: Epoch 929 accuracy None\n",
      "TRAINNING: Epoch 930 accuracy None\n",
      "TRAINNING: Epoch 931 accuracy None\n",
      "TRAINNING: Epoch 932 accuracy None\n",
      "TRAINNING: Epoch 933 accuracy None\n",
      "TRAINNING: Epoch 934 accuracy None\n",
      "TRAINNING: Epoch 935 accuracy None\n",
      "TRAINNING: Epoch 936 accuracy None\n",
      "TRAINNING: Epoch 937 accuracy None\n",
      "TRAINNING: Epoch 938 accuracy None\n",
      "TRAINNING: Epoch 939 accuracy None\n",
      "TRAINNING: Epoch 940 accuracy None\n",
      "TRAINNING: Epoch 941 accuracy None\n",
      "TRAINNING: Epoch 942 accuracy None\n",
      "TRAINNING: Epoch 943 accuracy None\n",
      "TRAINNING: Epoch 944 accuracy None\n",
      "TRAINNING: Epoch 945 accuracy None\n",
      "TRAINNING: Epoch 946 accuracy None\n",
      "TRAINNING: Epoch 947 accuracy None\n",
      "TRAINNING: Epoch 948 accuracy None\n",
      "TRAINNING: Epoch 949 accuracy None\n",
      "TRAINNING: Epoch 950 accuracy None\n",
      "Epoch 950 accuracy 0.7057416439056396\n",
      "TRAINNING: Epoch 951 accuracy None\n",
      "TRAINNING: Epoch 952 accuracy None\n",
      "TRAINNING: Epoch 953 accuracy None\n",
      "TRAINNING: Epoch 954 accuracy None\n",
      "TRAINNING: Epoch 955 accuracy None\n",
      "TRAINNING: Epoch 956 accuracy None\n",
      "TRAINNING: Epoch 957 accuracy None\n",
      "TRAINNING: Epoch 958 accuracy None\n",
      "TRAINNING: Epoch 959 accuracy None\n",
      "TRAINNING: Epoch 960 accuracy None\n",
      "TRAINNING: Epoch 961 accuracy None\n",
      "TRAINNING: Epoch 962 accuracy None\n",
      "TRAINNING: Epoch 963 accuracy None\n",
      "TRAINNING: Epoch 964 accuracy None\n",
      "TRAINNING: Epoch 965 accuracy None\n",
      "TRAINNING: Epoch 966 accuracy None\n",
      "TRAINNING: Epoch 967 accuracy None\n",
      "TRAINNING: Epoch 968 accuracy None\n",
      "TRAINNING: Epoch 969 accuracy None\n",
      "TRAINNING: Epoch 970 accuracy None\n",
      "TRAINNING: Epoch 971 accuracy None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINNING: Epoch 972 accuracy None\n",
      "TRAINNING: Epoch 973 accuracy None\n",
      "TRAINNING: Epoch 974 accuracy None\n",
      "TRAINNING: Epoch 975 accuracy None\n",
      "TRAINNING: Epoch 976 accuracy None\n",
      "TRAINNING: Epoch 977 accuracy None\n",
      "TRAINNING: Epoch 978 accuracy None\n",
      "TRAINNING: Epoch 979 accuracy None\n",
      "TRAINNING: Epoch 980 accuracy None\n",
      "TRAINNING: Epoch 981 accuracy None\n",
      "TRAINNING: Epoch 982 accuracy None\n",
      "TRAINNING: Epoch 983 accuracy None\n",
      "TRAINNING: Epoch 984 accuracy None\n",
      "TRAINNING: Epoch 985 accuracy None\n",
      "TRAINNING: Epoch 986 accuracy None\n",
      "TRAINNING: Epoch 987 accuracy None\n",
      "TRAINNING: Epoch 988 accuracy None\n",
      "TRAINNING: Epoch 989 accuracy None\n",
      "TRAINNING: Epoch 990 accuracy None\n",
      "TRAINNING: Epoch 991 accuracy None\n",
      "TRAINNING: Epoch 992 accuracy None\n",
      "TRAINNING: Epoch 993 accuracy None\n",
      "TRAINNING: Epoch 994 accuracy None\n",
      "TRAINNING: Epoch 995 accuracy None\n",
      "TRAINNING: Epoch 996 accuracy None\n",
      "TRAINNING: Epoch 997 accuracy None\n",
      "TRAINNING: Epoch 998 accuracy None\n",
      "TRAINNING: Epoch 999 accuracy None\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(1000):\n",
    "        t = sess.run(optimize_, feed_dict = {x_ : train_x, y_ : train_y})\n",
    "        print('TRAINNING: Epoch {} accuracy {}'.format(i, t))\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            acc_p = sess.run(acc_, feed_dict = {x_: test_x, y_ : test_y })\n",
    "            print('Epoch {} accuracy {}'.format(i, acc_p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
